[
  {
    "objectID": "Binning.html",
    "href": "Binning.html",
    "title": "Genomas a partir de metagenomas",
    "section": "",
    "text": "La metagen√≥mica hace referencia a todo el ADN de los organismos que se encuentran en un ambiente. La secuenciaci√≥n de este material gen√©tico produce lecturas que pueden ensamblarse para conocer la diversidad microbiana y sus funciones.\nT√≠picamente los metagenomas pueden estudiarse mediante dos aproximaciones:\nEn este apartado nos enfocaremos en la segunda aproximaci√≥n. Los MAGs se reconstruyen a partir de un ensamble metagen√≥mico, los contigs de dicho ensamble se agrupan mediante la informaci√≥n de cobertura y frecuencia de tetranucle√≥tidos. Esta agrupaci√≥n puede generar errores, por lo que es indispensable evaluar la calidad de los MAGs mediante la completitud y redundancia de genes de copia √∫nica (MerenLab y col.)\nPara obtener MAGs podemos seguir el siguiente flujo de an√°lisis:"
  },
  {
    "objectID": "Binning.html#binning",
    "href": "Binning.html#binning",
    "title": "Genomas a partir de metagenomas",
    "section": "Binning",
    "text": "Binning\nEn la secci√≥n anterior aprendimos como evaluar la calidad, filtrar las lecturas y a ensamblarlas, por lo que este apartado comenzar√° con el ensamble ya generado.\nDe acuerdo con el flujo de an√°lisis (Figura 2), debemos partir de un ensamble y mapear las lecturas a dicho ensamble para obtener un archivo de profundidad de cada contig en el ensamble.\n\n\n\n\n\n\nNota\n\n\n\nEl proceso de mapeo es demandante en tiempo de ejecuci√≥n y recursos. As√≠ que nos dimos a la tarea de generar el archivo de profundidad para comenzar directamente con el binning.\nEl mapeo lo corrimos con bowtie2 que es una herramienta confiable y muy utilizada para alinear lecturas cortas a una referencia, en nuestro caso, la referencia es el ensamble metagen√≥mico de la muestra de 48hrs. Bowtie2 genera un archivo de mapeo (SAM) que debe convertirse a un formato binario (BAM), para esta conversi√≥n usamos samtools que contiene multiples subherramientas para trabajar con archivos de mapeos.\nPara generar este archivo se utilizaron las siguientes lineas de c√≥digo.\n# Formatear el ensamble\nbowtie2-build results/02.ensambles/megahit/48hrs/48hrs.fasta results/03.profundidad/48hrs --threads 40\n# Mapear las lecturas contra el ensamble\nbowtie2 -x results/03.profundidad/48hrs -1 data/48hrs_sm_R1.fastq -2 data/48hrs_sm_R2.fastq -p 40 -S results/03.profundidad/48hrs.sam\n# Convertir de SAM a BAM y ordenar\nsamtools view -Sb -O BAM -@ 40 results/03.profundidad/48hrs.sam | samtools sort -@ 40  -o results/03.profundidad/48hrs_sorted.bam\n# Obtener el √≠ndice\nsamtools index results/03.profundidad/48hrs_sorted.bam\nYa que generamos el archivo bam ordenado y el √≠ndice obtuvimos un archivo con la informaci√≥n de cobertura de cada contig dentro del ensamble, este archivo de profundidad se gener√≥ con jgi_summarize_bam_contig_depths que es una herramienta de metabat.\n# jgi\n#Obtener el archivo de profundidad de cada contig\njgi_summarize_bam_contig_depths  --outputDepth results/03.profundidad/48hrs.mgh_depth.txt results/03.profundidad/48hrs_sorted.bam\n\n\n\n\n\n\nAtenci√≥n\n\n\n\nNo las ejecutes, s√≥lo son un ejemplo para que las puedas usar con tus propios datos en el futuro.\n\n\n\n\n\n\n\n\n\n\n\n\nEjercicio 1\n\n\n\nAntes de comenzar, re√∫nete con tu equipo y juntos\n\nrevisen el contenido de los directorios 02.ensambles y 03.profundidad.txt\nDiscutan y en una diapositiva expliquen el flujo que se sigui√≥ para obtener los archivos que estan esos directorios\n\nLa liga de drive para ir trabajando durante el taller es esta: https://drive.google.com/drive/folders/1iKfhMz_JdfImmsCmkPg10r-NC-nrzhQ4?usp=sharing\n\n\n\n\nPor si te pierdes\nS√≥lo por si te pierdes\n\n\n\n\n\n\nDirectorio de trabajo\n\n\n\nSi en alg√∫n momento te pierdes entre directorios, puedes regresar al espacio principal asi:\ncd && cd taller_metagenomica_pozol/\n\n\nAhora si, vamos a agrupar los contigs del metaensamble en bins ‚Ä¶\n\n\nMetabat2\nMetabat2 es una herramienta que agrupa los contigs tomando la cobertura de cada contig y calcula su composici√≥n nucleot√≠dica.\nPara correr metabat necesitamos activar el ambiente conda donde se aloja.\n\n\n\n\n\n\nActivar ambiente para Metabat2\n\n\n\n\nbetterlab\nconda activate binning\n\n\n\n\n\n\nMetabat2. Kang et al., 2015. DOI:10.7717/peerj.1165\n\n\nAhora que ya tenemos el ambiente activado ejecutemos la siguiente linea:\nmetabat2 -i results/02.ensambles/48hrs.fasta -a results/03.profundidad/48hrs.mgh_depth.txt -o results/04.metabat/metabat -t 4 -m 1500\n\n\n\n\n\n\nResponde:\n\n\n\n\n\n\n¬øCu√°ntos bins se formaron?\n\n2. ¬øQu√© par√°metros cambiar√≠as o agregar√≠as?\n\n\n\n\n\n\nAyuda\n\n\n\n\n\n\nls results/04.metabat/\nmetabat2 ‚Äì-help\n\n\n\n\n\n\n\nYa que corrimos Metabat2 vamos a ejecutar MaxBin2, pero primero necesitamos desactivar el ambiente:\n\n\n\n\n\n\nDesactiva el ambiente\n\n\n\nPara desactivar el ambiente debemos correr la siguiente linea:\nconda deactivate\n\n\n\n\nMaxBin2\nMaxBin2 agrupa los contigs de acuerdo a la informaci√≥n de cobertura, composici√≥n nucleot√≠dica y genes de marcadores de copia √∫nica.\nVamos a ejecutarlo, activemos el ambiente conda para maxbin.\n\n\n\n\n\n\nActivar ambiente para MaxBin2\n\n\n\n\nbetterlab\nconda activate metagenomics\n\n\n\n\n\n\nMaxBin2. Wu et al., 2014. https://doi.org/10.1186/2049-2618-2-26\n\n\nCrea el directorio para los resultados de MaxBin2\nmkdir -p results/05.maxbin\nAhora si, vamos a ejecutarlo.\n\nrun_MaxBin.pl -thread 4 -min_contig_length 1500 -contig results/02.ensambles/48hrs.fasta -out results/05.maxbin/48hrs_maxbin -abund results/03.profundidad/48hrs.mgh_depth.txt\n\n\n\n\n\n\nEjercicio:\n\n\n\n\n\n1. ¬øCu√°ntos bins se formaron?\n2. ¬øQu√© porcentaje de completitud y contaminaci√≥n tienen??\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nls results/05.maxbin/*.fasta | wc -l\ncat results/05.maxbin/48hrs_maxbin.summary | column -t\n\n\n\n\n\n\n\n\n\n\n\n\n\nDesactiva el ambiente\n\n\n\nconda deactivate\n\n\n\n\nVamb\nVAMB utiliza una combinaci√≥n de enfoques de aprendizaje profundo y t√©cnicas de agrupamiento bas√°ndose en sus patrones de composici√≥n de nucle√≥tidos y en la co-ocurrencia de sus frecuencias de cobertura.\n\n\n\n\n\n\nActiva el ambiente binning\n\n\n\n\nbetterlab\nconda activate binning\n\n\n\nVamos a correr vamb, pero primero crea el directorio de resultados\nmkdir -p results/06.vamb\nEjecutemos vamb:\nvamb --fasta results/02.ensambles/48hrs.fasta --jgi results/03.profundidad/48hrs.mgh_depth.txt --minfasta 500000 --outdir results/06.vamb/48hrs\n\n\n\n\n\n\nImportant\n\n\n\nSi quisieras recuperar los genomas de virus ¬øQu√© par√°metro cambiar√≠as?\n\n\n\n\n\n\n\n\nOtros programas para binning\n\n\n\nRecientemente se public√≥ COMEBin, que utiliza un enfoque distinto a lo que hemos usado en este tutorial. En el siguiente link encontrar√°s el manual y una explicaci√≥n general sobre su funcionamiento."
  },
  {
    "objectID": "Binning.html#refinamiento",
    "href": "Binning.html#refinamiento",
    "title": "Genomas a partir de metagenomas",
    "section": "Refinamiento",
    "text": "Refinamiento\nYa corrimos tres programas de binning, pero, recordemos que los agrupamientos pueden tener errores:\n\n\n\nContaminaci√≥n de bins\n\n\nPara disminuir la contaminaci√≥n e incrementar la completitud hay algunos programas que pueden ayudarnos. entre ellos est√°n Binning_refiner y DASTool.\n\nCheckM\nAntes de proceder al refinamiento es necesario tener claro c√≥mo se eval√∫a la completitud y contaminaci√≥n de los bins. Para esta evaluaci√≥n se usa CheckM que se ha convertido en una herramienta est√°ndar para la evaluaci√≥n de la calidad de genomas y MAGs, y es usada por la mayor√≠a de programas de refinamiento.\nPara hacer esta evaluaci√≥n, CheckM utiliza una serie de herramientas: tree organiza los genomas en un √°rbol de referencia. tree_qa eval√∫a la cantidad de genes marcadores filogen√©ticos y su ubicaci√≥n en el √°rbol. El comando lineage_set crea un archivo de marcadores espec√≠ficos de linaje, que se usa en el comando analyze para evaluar la integridad y contaminaci√≥n de los genomas. Finalmente, el comando qa genera tablas que resumen la calidad de los genomas.\n\n\n\nCheckM Workflow\n\n\nEn este taller no vamos a correr CheckM porque los programas de refinamiento que usaremos ya lo corren de forma interna, sin embargo, es √∫til correrlo para tener una idea clara sobre la calidad de los bins que obtengamos.\nTe dejamos la siguiente l√≠nea para que la uses en tus proyectos.\n#ejemplo de como correrlo con los bins de vamb\n#se debe activar el ambiente metagenomics\n#checkm lineage_wf results/06.vamb/48hrs/bins results/checkm/ -x fna -t 4  -f results/checkm/checkm_vamb_bins.txt\nY una captura de ejemplo de como se ve la salida de CheckM:\n\n\n\n\n\nY ahora si, a refinar los bins ‚Ä¶ ü•≥\n\n\nBinning_refiner\nBinning_refiner se enfoca en refinar y fusionar los bins para mejorar la integridad y reducir la contaminaci√≥n. Identifica bins que pueden representar el mismo genoma y los fusiona. Despu√©s elimina posibles contaminaciones, durante el proceso, Binning_refiner eval√∫a la calidad de los bins.\n\n\n\nBinning_refiner\n\n\nhttps://doi.org/10.1093/bioinformatics/btx086\nNecesitamos crear el directorio de resultados para binning_refiner y un directorio con los bins generados por cada programa\nmkdir -p results/07.binning_refiner/48hrsbins/{metabat,maxbin,vamb}\nAhora vamos a crear ligas simb√≥licas de los bins generados por cada herramienta.\n#metabat\ncd results/07.binning_refiner/48hrsbins/metabat/\n\nln -s ../../../04.metabat/*.fa .\n\n#maxbin\ncd ../maxbin/\nln -s ../../../05.maxbin/*.fasta .\n\n# vamb\ncd ../vamb/\nln -s ../../../06.vamb/48hrs/bins/*.fna .\n\n\n#regresar\ncd ../../\nAhora si, corramos Binning_refiner\nBinning_refiner -i 48hrsbins/ -p 48hrs\nY regresemos a nuestro directorio principal\ncd && cd taller_metagenomica_pozol/\nExploremos los resultados!\ncat results/07.binning_refiner/48hrs_Binning_refiner_outputs/48hrs_sources_and_length.txt\nRefined_bin     Size(Kbp)       Source\n48hrs_1 1535.49 48hrs_maxbin.004.fasta,metabat.5.fa,676.fna\n48hrs_2 1506.01 48hrs_maxbin.002.fasta,metabat.3.fa,6952.fna\n48hrs_3 1319.12 48hrs_maxbin.008.fasta,metabat.2.fa,28067.fna\n48hrs_4 1263.79 48hrs_maxbin.005.fasta,metabat.9.fa,3736.fna\n48hrs_5 1185.25 48hrs_maxbin.001.fasta,metabat.11.fa,15732.fna\n48hrs_6 1052.67 48hrs_maxbin.003.fasta,metabat.4.fa,15732.fna\n48hrs_7 557.49  48hrs_maxbin.006.fasta,metabat.1.fa,28990.fna\nCopia y pega este contenido en la consola de Rscript\n# Cargar las librerias\nlibrary(dplyr)\nlibrary(networkD3)\n\n# revisa tu ubicaci√≥n\ngetwd()\nsetwd(\"/home/ELALUMNOQUEERES/taller_metagenomica_pozol\")\n\n# Cargar los datos\nsankey_data &lt;- read.csv(\"results/07.binning_refiner/48hrs_Binning_refiner_outputs/48hrs_sankey.csv\")\n\n# Crear una lista de nodos √∫nicos\nnodes &lt;- data.frame(name = unique(c(sankey_data$C1, sankey_data$C2)))\n\n# Crear el dataframe de enlaces\nlinks &lt;- sankey_data %&gt;%\n  mutate(source = match(C1, nodes$name) - 1,\n         target = match(C2, nodes$name) - 1,\n         value = Length_Kbp) %&gt;%\n  select(source, target, value)\n\n# Crear el gr√°fico Sankey\nsankey_plot &lt;- sankeyNetwork(Links = links, Nodes = nodes,\n                             Source = \"source\", Target = \"target\",\n                             Value = \"value\", NodeID = \"name\",\n                             fontSize = 12, nodeWidth = 30)\n\n# Mostrar el gr√°fico\nsankey_plot\n\n# Guardar\nlibrary(htmlwidgets)\nsaveWidget(sankey_plot, file = \"48hrs_sankey_plot.html\")\n\n\n\nBinning_refiner sankey plot\n\n\n\n\nDASTool\nDASTool es una herramienta utilizada para mejorar la calidad de los bins. Eval√∫a la integridad, combina los resultados de diferentes bineadores y por consenso selecciona los mejores bins de cada herramienta. Una vez que DASTool ha seleccionado los mejores bins, realiza un proceso de refinamiento para optimizar los resultados.\n\n\n\nDASTool\n\n\nVamos a correr DASTool ‚Ä¶\nPrimero crea el directorio para los resultados\nmkdir -p results/08.dastool\nDASTool necesita como entrada un archivo tabular con informaci√≥n de los resultados de cada programa de binning.\nFasta_to_Contig2Bin.sh -i results/04.metabat/ -e fa &gt; results/08.dastool/48hrs_metabat.dastool.tsv\n\nFasta_to_Contig2Bin.sh -i results/05.maxbin/ -e fasta &gt; results/08.dastool/48hrs_maxbin.dastool.tsv\n\nFasta_to_Contig2Bin.sh -i results/06.vamb/48hrs/bins/ -e fna &gt; results/08.dastool/48hrs_vamb.dastool.tsv\nYa que tenemos los archivos tsv podemos empezar con el refinamiento!! ü•≥\nDAS_Tool -i results/08.dastool/48hrs_metabat.dastool.tsv,results/08.dastool/48hrs_maxbin.dastool.tsv,results/08.dastool/48hrs_vamb.dastool.tsv -l metabat,maxbin,vamb -c results/02.ensambles/48hrs.fasta -o results/08.dastool/48hrs -t 4 --write_bins"
  },
  {
    "objectID": "Binning.html#dereplicaci√≥n",
    "href": "Binning.html#dereplicaci√≥n",
    "title": "Genomas a partir de metagenomas",
    "section": "Dereplicaci√≥n",
    "text": "Dereplicaci√≥n\n\ndRep\nLa desreplicaci√≥n es el proceso de identificar conjuntos de genomas que son ‚Äúiguales‚Äù en una lista de genomas y eliminar todos los genomas excepto el ‚Äúmejor‚Äù de cada conjunto redundante. dRep es una herramienta √∫til para esto.\n\n\n\ndRep\n\n\nYa que tenemos los resultados de los dos refinadores ejecutaremos dRep para desreplicar y seleccionar el mejor representante de cada bin.\nPrimero vamos a crear el directorio de resultados para dRep.\nmkdir -p results/09.drep/bins\nY entraremos al directorio bins dentro del directorio de resultados para colocar los bins que queremos comparar. En este caso los generados por ambos refinadores.\ncd results/09.drep/bins/\nCon las siguientes lineas podemos copiar los bins en este directorio:\nfor i in $(ls ../../08.dastool/48hrs_DASTool_bins/*.fa) ; do name=$(basename $i .fa); cp $i $name\".fasta\" ; done\n\ncp ../../07.binning_refiner/48hrs_Binning_refiner_outputs/48hrs_refined_bins/*.fasta .\nYa que los copiamos, regresemos al directorio principal.\ncd && cd taller_metagenomica_pozol/\nY ahora si, vamos a correr dRep ‚Ä¶\n\nexport PATH=/miniconda3/envs/metagenomics/bin:$PATH\ndRep dereplicate results/09.drep/ -d -comp 50 -con 10 --SkipSecondary -g results/09.drep/bins/*.fasta\nEste es uno de los plots generados por dRep, que representa los mejores bins desreplicados.\n\n\n\ndRepWinningGenomes\n\n\nVamos a desactivar el ambiente de dRep\nconda deactivate\n\n\n\n\n\n\n\nPara reflexionar\n\n\n\nQu√© har√≠as si antes de desreplicar tienes un bin que tiene 98 % de completitud y 11 % de contaminaci√≥. dRep en autom√°tico lo descartar√≠a.\nPropondr√≠as alguna manera para quedarte con este bin y curarlo para reducir su contaminaci√≥n?\nPor suerte hay m√°s programas que pueden ayudarnos a curar nuestros bins manualmente, una herramienta √∫til para esto es mmgenome2\n\n\nPara tomar en consideraci√≥n:\n\n\n\n\n\n\nTip\n\n\n\nYa que tenemos los bins refinados y desreplicados opcionalmente podr√≠as reensamblarlos. La manera ser√≠a mapear las lecturas de toda la muestra a los bins finales y con las lecturas mapeadas y el bin generar un ensamble gen√≥mico para cada uno. Con esta aproximaci√≥n se genera un MAG m√°s pulido y la contaminaci√≥n se reduce.\nAunque en muchos reportes ver√°s que los autores reensamblan sus MAGs, en otros no lo hacen y no hacerlo no est√° mal, hacerlo mejora la calidad.\n\n\n\nAhora te toca a t√≠\n\n\n\n\n\n\nEjercicio 2\n\n\n\nAhora te toca a t√≠.\n\nRe√∫nanse en equipos y repliquen todo el flujo hasta este punto con la muestra que les toca.\nDiscutan cada resultado obtenido.\nEn la carpeta compartida de Drive busquen la presentaci√≥n para el Ejercicio 2, en la diapositiva correspondiente resuman sus resultados obtenidos para que los presenten.\n\nTiempo de actividad (1 hr)\nTiempo de presentaci√≥n de resultados (5 min por equipo)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "El pozol",
    "section": "",
    "text": "El pozol es un alimento √°cido, fermentado a partir de ma√≠z nixtamalizado, de importancia econ√≥mica y cultural, se consume desde tiempos prehisp√°nicos y se ha estudiado desde los a√±os 70s.\nAlgunos puntos importantes que conocemos son:\n\n\nNo se inocula y al final de su fermentaci√≥n tiene alta diversidad microbiana.\nEs muy nutritivo, tiene un alto contenido de amino√°cidos esenciales.\nEs considerado como prebi√≥tico, contiene fibras solubles y microorganismos ben√©ficos para la salud intestinal humana.\n\n\n\nüß¨üîäü¶† Imaginemos que se quiere impulsar la producci√≥n de esta bebida y para ello necesitan saber todo acerca de su naturaleza microbiana.\nUna importante industria alimenticia los contacta como expertos en ecolog√≠a microbiana y les pide ayuda para descubrir los siguientes puntos:\n\n\n¬øQu√© actores microbianos est√°n presentes durante el proceso de fermentaci√≥n?\n¬øC√≥mo ocurre la bioconversi√≥n del ma√≠z durante la fermentaci√≥n, qui√©n participa y c√≥mo lo hace? ¬øQu√© funciones metab√≥licas est√°n ocurriendo?\n¬øCambia la comunidad microbiana a lo largo del proceso?\n\n\nLa empresa secuenci√≥ cuatro puntos de fermentaci√≥n de muestras que se obtuvieron en un mercado de Campeche. Las muestras se secuenciaron con Illumina NextSeq500 con lecturas pareadas de 75 pb.\n\n\n\n\n\n\n\nImportante\n\n\n\nComo las muestras contienen ma√≠z, es indispensable remover las lecturas que correspondan al genoma del ma√≠z, no hacerlo producir√° un ensamble muy fragmentado, mayoritariamente del ma√≠z y poco microbiano.\nEl autor del art√≠culo amablemente nos proporcion√≥ sus muestras libres del ma√≠z y el c√≥digo que us√≥ para ello est√° disponible en un repositorio p√∫blico de GitHub.\n\n\nEl art√≠culo: L√≥pez-S√°nchez et al., 2023. Analysing the dynamics of the bacterial community in pozol, a Mexican fermented corn dough. 10.1099/mic.0.001355"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Microbioma_del_pozol",
    "section": "",
    "text": "En este taller introductorio aprenderemos a reconstruir genomas a partir de metagenomas (MAGs), a clasificar los MAGs taxon√≥micamente y a predecir sus genes e inferir su metabolismo. Adem√°s, abordaremos un poco sobre el an√°lisis de amplicones del gene 16S ARNr."
  },
  {
    "objectID": "index.html#taller-introductorio-al-an√°lisis-de-metagenomas-centrado-en-genomas-y-an√°lisis-de-amplicones-del-gene-16s-arnr.",
    "href": "index.html#taller-introductorio-al-an√°lisis-de-metagenomas-centrado-en-genomas-y-an√°lisis-de-amplicones-del-gene-16s-arnr.",
    "title": "Microbioma_del_pozol",
    "section": "",
    "text": "En este taller introductorio aprenderemos a reconstruir genomas a partir de metagenomas (MAGs), a clasificar los MAGs taxon√≥micamente y a predecir sus genes e inferir su metabolismo. Adem√°s, abordaremos un poco sobre el an√°lisis de amplicones del gene 16S ARNr."
  },
  {
    "objectID": "index.html#temario",
    "href": "index.html#temario",
    "title": "Microbioma_del_pozol",
    "section": "Temario",
    "text": "Temario\nD√≠a 3\n\n\n\nHora\nTema\n\n\n\n\n9:00 - 9:30\nReconstrucci√≥n de genomas\n\n\n9:30 - 9:50\n¬øQu√© es el binning?\n\n\n9:50 - 10:00\nDescanso\n\n\n10:00 - 12:15\nReconstrucci√≥n de genomas\n\n\n12:15 - 12:30\nDescanso\n\n\n12:30 - 13:30\nEjercicio por equipo\n\n\n13:30 - 14:00\nDiscusi√≥n de resultados\n\n\n14:00 - 15:30\nComida\n\n\n15:30 - 16:00\nDereplicaci√≥n\n\n\n16:00 - 17:00\nClasificaci√≥n taxon√≥mica\n\n\n\nD√≠a 4\n\n\n\n\n\n\n\nHora\nTema\n\n\n\n\n9:00 - 10:00\nPredicci√≥n g√©nica\n\n\n10:00 - 10:30\nPl√°tica sobre el microbioma del chinicuil\n\n\n10:30 - 10:45\nDescanso\n\n\n10:45 - 12:00\nRbims\n\n\n12:00 - 12:15\nDescanso\n\n\n12:15 - 14:00\nOtras inferencias metab√≥licas y discusi√≥n de resultados\n\n\n14:00 - 15:30\nComida\n\n\n15:30 - 17:00\nVistazo a la reconstrucci√≥n viral y eucari√≥tica\n\n\n\nD√≠a 5\n\n\n\n\n\n\n\nHora\nTema\n\n\n\n\n9:00 - 10:00\nIntroducci√≥n al an√°lisis de amplicones\n\n\n10:00 - 10:30\nIntroducci√≥n a QIIME2\n\n\n10:30 - 10:45\nDescanso\n\n\n10:45 - 12:00\nImportaci√≥n de datos e inferencia de ASVs\n\n\n12:00 - 12:15\nDescanso\n\n\n12:15 - 14:00\nAsignaci√≥n taxon√≥mica, limpieza e inferencia filogen√©tica\n\n\n14:00 - 15:30\nComida\n\n\n15:30 - 17:00\nImportaci√≥n a R, gr√°ficos y diversidad"
  },
  {
    "objectID": "Project.html",
    "href": "Project.html",
    "title": "Preparemos todo para el proyecto",
    "section": "",
    "text": "Reglas del juego\n\n\n\n\nEn este tutorial haremos el ejemplo corriendo la muestra de 48 hrs.\nSe formaran 6 equipos (2 de los tiempos 0, 9 y 24 hrs).\nLos equipos discutir√°n y presentar√°n sus resultados cuando se indique en el tutorial."
  },
  {
    "objectID": "Project.html#espacio-de-trabajo",
    "href": "Project.html#espacio-de-trabajo",
    "title": "Preparemos todo para el proyecto",
    "section": "Espacio de trabajo",
    "text": "Espacio de trabajo\n\nEntra a tu cuenta en el servidor y sit√∫ate en tu $HOME\nObten los datos y la estructura de tu directorio del proyecto corriendo lo siguiente:\n\n# ve al $HOME\ncd\n# copia los directorios de trabajo\n# metagen√≥mica\ncp -r /home/alumno1/taller_metagenomica_pozol .\n# amplicones\ncp -r /home/alumno1/taller_amplicones_pozol .\n\nEntra al directorio del proyecto\n\ncd taller_metagenomica_pozol\n\n\n\n\n\n\nDirectorio de trabajo\n\n\n\nSi en alg√∫n momento te pierdes entre directorios, puedes regresar al espacio principal asi:\ncd && cd taller_metagenomica_pozol/\n\n\n\n\nLa presente pr√°ctica s√≥lo es una representaci√≥n del flujo de trabajo para el an√°lisis metagen√≥mico, sin embargo, no sustituye los manuales de cada programa y el flujo puede variar dependiendo del tipo de datos y pregunta de investigaci√≥n, de hecho para fines del taller, con frecuencia se utilizan las lineas de comando m√°s simples para eficientar tiempo y recursos, t√≥malo en cuenta.\n\nCada programa tiene una ayuda y un manual de usuario, es importante revisarlo y conocer cada par√°metro que se ejecute. En terminal se puede consultar el manual con el comando man y tambi√©n se puede consultar la ayuda con -h o --help, por ejemplo fastqc -h.\n\n\n\n\n\n\nImportant\n\n\n\nüß† Para tenerlo presente\nEn bioinform√°tica cualquier l√≠nea de comandos generar√° un resultado, de ah√≠ a que esos resultados sean correctos puede haber una gran diferencia.\nEn cada paso detente a revisar la informaci√≥n de cada programa, lee el manual, visita foros de ayuda y selecciona los argumentos que se ajusten a las necesidades de tus datos."
  },
  {
    "objectID": "metabolic.html",
    "href": "metabolic.html",
    "title": "Metabolismo",
    "section": "",
    "text": "Ahora que ya tenemos los bins refinados, queremos saber qu√© capacidades metab√≥licas poseen. Para ello es necesario predecir sus genes y asignarles funci√≥n.\n\nPROKKA\nProkka es una herramienta √∫til, usa diferentes programas para predecir genes, secuencias codificantes, tRNAs, rRNAs. Hace la traducci√≥n de CDS a amino√°cidos y asigna funciones usando varias bases de datos.\n\n\n\n\n\nPara correrlo vamos a activar el ambiente en el que se aloja.\n\n\n\n\n\n\nActiva el ambiente para PROKKA\n\n\n\nconda activate Prokka_Global\n\n\nTenemos el ambiente activo, ahora vamos a crear un directorio de resultados para prokka.\nmkdir -p results/11.prokka\nPara correrlo, podemos hacer un ciclo que nos permita anotar todos los bins.\nfor FASTA in $(ls results/10.gtdbtk/bins/); do LOCUSTAG=$(basename $FASTA .fasta); prokka --locustag \"${LOCUSTAG}_Scaffold --prefix $LOCUSTAG --addgenes --addmrn --cpus 4 --outdir \"results/11.prokka/$LOCUSTAG\" \"results/10.gtdbtk/bins/$FASTA\" ;\ndone\n\n\n\n\n\n\nExplora\n\n\n\nMientras prokka se ejecuta en los bins que obtuviste, despliega la ayuda y discute:\n\n¬ø qu√© argumentos quitar√≠as o agregar√≠as?\nCu√°les te llamaron la atenci√≥n?\n\n\n\nDesactivemos el ambiente:\nconda deactivate\nAhora que tenemos las prote√≠nas predichas vamos a obtener m√°s anotaciones √∫tiles, usaremos kofam para esto.\n\n\nKofamScan\nKofamScan es una herramienta de anotaci√≥n, usa la base de datos KOfam de KEGG para obtener informaci√≥n sobre los genes que participan en diferentes rutas metab√≥licas.\nVamos a crear el directorio de resultados\nmkdir -p results/12.kofam\n\n\n\n\n\n\nEjemplo de como correr KOfamScan\n\n\n\nGHH\nKofamScan requiere mucho tiempo de ejecuci√≥n. Para efectos del taller nosotros ya lo corrimos y te proporcionaremos los resultados. Pero te dejamos el bloque de c√≥digo que usamos para este paso.\nfor FAA in $(ls results/11.prokka/*/*.faa); do\n    name=$(basename $FAA .faa)\n    exec_annotation $FAA \\\n        -o results/12.kofam/\"$name.txt\" \\\n        --report-unannotated \\\n        --cpu 4 \\\n        --tmp-dir results/12.kofam/\"tmp$name\" \\\n        -p /home/alumno1/kofam/db/profiles/ \\\n        -k /home/alumno1/kofam/db/ko_list\ndone\n# remover los directorios temporales\n#rm -r results/12.kofam/tmp*\n\n\nEstos resultados ya los tienes en el directorio results/12.kofam\nY ahora que ya tenemos los identificadores de KO para cada prote√≠na, vamos a filtrar y graficar el metabolismo de los bins.\n\n\nRbiMs\nRbiMs es un paquete de R muy √∫til para obtener la anotaci√≥n de cada KEGG ID y generar plots de esta informaci√≥n. Puede trabajar con anotaciones de KOFAM, Interpro o PFAM.\n\n\n\nRbiMs\n\n\nVamos al editor de Rstudio para correr RbiMs ‚ú®\nlibrary(tidyverse)\nlibrary(tidyr)\nlibrary(rbims)\nlibrary(readxl)\n\n#setwd(\"/home/alumnoX/taller_metagenomica_pozol/\")\n\n#A continuaci√≥n, leemos los resultados de KEGG \npozol_table &lt;- read_ko(data_kofam = \"results/12.kofam/\") \n\n#y los mapeamos con la base de datos de KEGG:\npozol_mapp &lt;- mapping_ko(pozol_table)\n\n#Nos centraremos en las v√≠as metab√≥licas relacionadas con la biosintesis de aminoacidos y vitaminas:\n\nOverview &lt;- c(\"Biosynthesis of amino acids\", \"Vitamin B6 metabolism\")\nAminoacids_metabolism_pozol &lt;- pozol_mapp %&gt;%\n  drop_na(Module_description) %&gt;%\n  get_subset_pathway(Pathway_description, Overview) \n\n#Visualizamos los datos con un gr√°fico de burbujas:\n\nplot_bubble(tibble_ko = Aminoacids_metabolism_pozol,\n            x_axis = Bin_name, \n            y_axis = Pathway_description,\n            analysis = \"KEGG\",\n            calc = \"Percentage\",\n            range_size = c(1, 10),\n            y_labs = FALSE,\n            x_labs = FALSE)  \n\n#A√±adiremos metadatos, como la taxonom√≠a:\n\nMetadatos &lt;- read_delim(\"results/10.gtdbtk/Metadatos.txt\", delim = \"\\t\")\n\n#Y generaremos un gr√°fico de burbujas con metadatos:\n\nplot_bubble(tibble_ko = Aminoacids_metabolism_pozol,\n            x_axis = Bin_name, \n            y_axis = Pathway_description,\n            analysis = \"KEGG\",\n            data_experiment = Metadatos,\n            calc = \"Percentage\",\n            color_character = Family,\n            range_size = c(1, 10),\n            y_labs = FALSE,\n            x_labs = FALSE) \n\n# Exploraci√≥n de una V√≠a Espec√≠fica\n# podemos explorar una sola v√≠a, como el ‚ÄúSecretion system,‚Äù y crear un mapa de calor para visualizar los genes relacionados con esta v√≠a:\n\nSecretion_system_pozol &lt;- pozol_mapp %&gt;%\n  drop_na(Cycle) %&gt;%\n  get_subset_pathway(Cycle, \"Secretion system\")\n\n#Y, finalmente, generamos un mapa de calor:\n\nplot_heatmap(tibble_ko = Secretion_system_pozol, \n             y_axis = Genes,\n             analysis = \"KEGG\",\n             calc = \"Binary\")\n\n#Tambi√©n podemos agregar metadatos para obtener una visi√≥n m√°s completa:\n\nplot_heatmap(tibble_ko = Secretion_system_pozol, \n             y_axis = Genes,\n             data_experiment = Metadatos,\n             order_x = Family,\n             analysis = \"KEGG\",\n             calc = \"Binary\")\n\nplot_heatmap(tibble_ko = Secretion_system_pozol, \n             y_axis = Genes,\n             data_experiment = Metadatos,\n             order_y = Pathway_cycle,\n             order_x = Family,\n             analysis = \"KEGG\",\n             calc = \"Binary\")\n\n\n\n\n\n\n\nAntismash\nAdicionalmente podr√≠as anotar el metabolismo secundario de los bins siguiendo el flujo de an√°lisis propuestos en la lecci√≥n de Miner√≠a Gen√≥mica de Software Carpentry."
  },
  {
    "objectID": "gtdbtk.html",
    "href": "gtdbtk.html",
    "title": "Asignaci√≥n taxon√≥mica",
    "section": "",
    "text": "GTDB-tk\nGTDB-Tk es una herramienta que asigna taxonom√≠a a genomas utilizando la base de datos GTDB (Genome Taxonomy Database). Basado en √°rboles filogen√©ticos y medidas de ANI (Average Nucleotide Identity), GTDB-Tk clasifica genomas bacterianos y arqueanos, proporciona una taxonom√≠a coherente y actualizada. Se utiliza mucho en el an√°lisis de genomas y metagenomas.\n\n\n\nGTDB-tk Workflow\n\n\nRecordemos que ya tenemos un set de bins refinados y desreplicados. Ahora vamos a asignarles identidad taxon√≥mica, para ello vamos a correr GTDB-tk\n\n\n\n\n\n\nActiva el ambiente de gtdbtk\n\n\n\nconda activate gtdbtk-2.1.1\n\n\nEl directorio de resultados para gtdbtk ya lo tienes en tu carpeta de resultados. Para colocar los bins refinados y renombrados ejecuta el script `src/copiar_renombrarbins.sh` :\n bash src/copiar_renombrarbins.sh\nAhora si, vamos a correr gtdbtk\npip install numpy==1.19.5\n\ngtdbtk classify_wf --genome_dir results/10.gtdbtk/bins/ --out_dir results/10.gtdbtk/ --cpus 4 -x fasta\nNo olvides desactivar el ambiente\nconda deactivate\n\n\n\n\n\n\nResultado de GTDB-Tk\n\n\n\nSi gtdbtk est√° tomando mucho tiempo puedes parar el proceso con ctrl + C en tu teclado. El resultado final se encuentra en el directorio y archivo: results/10.gtdbtk/gtdbtk.bac120.summary.tsv que se copi√≥ desde el inicio.\n\n\nDespu√©s de ejecutar GTDB-tk, continuaremos en R para visualizar los datos.\nlibrary(tidyverse)\nlibrary(ggplot2)\n\nGTDBK &lt;- read.table(\"results/10.gtdbtk/gtdbtk.bac120.summary.tsv\", \n  sep = \"\\t\", header = TRUE, na.strings = \"\", stringsAsFactors = FALSE) %&gt;%\n  as_tibble()\n\n#El archivo contiene informaci√≥n sobre la clasificaci√≥n taxon√≥mica de los bins.\n#Continuamos limpiando y transformando los datos:\n\npozol_gtdbtk &lt;- GTDBK %&gt;%\n  select(user_genome, classification) %&gt;%\n  separate(classification, c(\"Domain\", \"Phylum\", \"Class\", \"Order\", \"Family\", \"Genus\", \"Species\"), sep = \";\") %&gt;%\n  rename(Bin_name = user_genome) %&gt;%\n  unite(Bin_name_2, c(\"Bin_name\", \"Phylum\"), remove = FALSE) %&gt;%\n  select(Bin_name, Domain, Phylum, Class, Order, Family, Genus, Species)\n\n#Guardamos los datos en un archivo de metadatos:\nwrite.table(pozol_gtdbtk, file = \"results/10.gtdbtk/Metadatos.txt\", sep = \"\\t\", quote = FALSE, row.names = FALSE, col.names = TRUE)\n\n#Visualizaci√≥n de Datos Creamos un gr√°fico de barras  que muestra la distribuci√≥n taxon√≥mica de los bins:\n\nGTDBtk_barplot &lt;- pozol_gtdbtk %&gt;%\n  count(Phylum, Genus) %&gt;%\n  rename(Number_of_MAGs = n) %&gt;%\n  ggplot(aes(x = Phylum, y = Number_of_MAGs, fill = Genus)) + \n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  theme_minimal()\n\nGTDBtk_barplot\n\n\n\n\n\n\nDiscusi√≥n\n\n\n\nEn equipos revisen los resultados generados por GTDB-tk y propongan un plan para mejorar la identificaci√≥n taxon√≥mica, qu√© har√≠an para darle m√°s soporte a estos resultados?"
  },
  {
    "objectID": "Amplicones16S.html",
    "href": "Amplicones16S.html",
    "title": "Amplicones 16S",
    "section": "",
    "text": "El an√°lisis de amplicones, tambi√©n llamado meta-taxonom√≠a y mal llamado metagen√≥mica. Se usa ampliamente para conocer la diversidad taxon√≥mica de un ambiente. Se amplifica y secuenc√≠a una regi√≥n de cada organismo que se encuentra en la comunidad. Estos marcadores pueden ser los genes ribosomales 16S, 18S, ITS o el COI, etc.\n\n\n\n\n\nExisten diversas herramientas para analizar este tipo de datos como Mothur, USEARCH, VSEARCH, Deblur, AMPtk, DADA2 en R, QIIME2, etc.\nEn este taller vamos a usar Qiime2 con DADA2 para inferir las ASVs"
  },
  {
    "objectID": "Creditos.html",
    "href": "Creditos.html",
    "title": "Cr√©ditos",
    "section": "",
    "text": "El contenido de esta p√°gina fue creado como parte del proyecto Ciencia de Frontera CBF2023-2024-1251 liderado por la Dra. Mirna Rosas V√°zquez Landa.\nAutoras: Diana Hern√°ndez Oaxaca @DianaOaxaca y Mirna Rosas V√°zquez Landa @MirnaVazquez .\nAgradecimientos:\n\nTodos los miembros del laboratorio LandaLab del Departamento de Ecolog√≠a Molecular y gen√≥mica poblacional del ICMyL de la UNAM, por la sugerencias a la mejora de este tutorial.\nAl M. en C. Rafael L√≥pez S√°nchez, por donar los datos de metagen√≥mica del pozol libres de ma√≠z y por revisar el material del taller.\nA la Dra. Nelly Sel√©m por brindar apoyo y acceso al servidor de trabajo.\nAl M. en C. Luis Gerardo Tejero G√≥mez de la unidad de computo del Centro de Ciencias Matem√°tica de la UNAM. Por su invaluable apoyo en la instalaci√≥n y soporte de las herramientas usadas en este taller.\n\n\nEl material de esta pr√°ctica inicialmente se prepar√≥ para los Talleres Internacionales de Bioinform√°tica (TIB2022) organizados por la Sociedad Mexicana de Bioinform√°tica (SMB) y la Comunidad de Desarrollo de Software Bioinform√°tico (CDSB). Se ha usado en talleres intersemestrales del Instituto de Ciencias del Mar y Limnolog√≠a (ICMyL) de la UNAM, el t√≥pico de posgrado Hackeando las comunidades microbianas. Cursos intensivos de posgrado del INECOL yel taller de metagen√≥mica de la Red Mexicana de Bioinform√°tica RMB organizado en el CIBNOR Junio 2024. El material se ha ido modificando con el tiempo y sigue en desarrollo."
  },
  {
    "objectID": "Recursos_extra.html",
    "href": "Recursos_extra.html",
    "title": "Recursos extra",
    "section": "",
    "text": "Metagen√≥mica\n\n\nAmplicones\nSi quieres profundizar en el an√°lisis de amplicones te recomendamos visitar\n\nTutoriales completos para el procesamiento de los datos, filtros y an√°lisis complementarios de Microbiome Helper y su art√≠culo asociado.\nTutoriales para usar el paquete Microbiome.\nFlujo completo de amplicones y otros rescursos de bioinform√°tica y gen√≥mica de Mike Lee.\nBases de datos para asignar taxonom√≠a en DADA2 dentro de R.\ncanal de youtube y/o los cursos y asesorias de microbioma-lab."
  },
  {
    "objectID": "Amplicones16S.html#srccreate_manifest.sh",
    "href": "Amplicones16S.html#srccreate_manifest.sh",
    "title": "Amplicones 16S",
    "section": "src/create_manifest.sh",
    "text": "src/create_manifest.sh\n#!/usr/bin/bash\n#Create manifest file\n\ncd results/01.cutadapt\n\nid=$(ls *.gz |  sed 's/_.*//g' | sort -u)\n\necho -e \"sample-id\"\",\"\"absolute-filepath\"\",\"\"direction\" &gt; ../../data/manifest.csv\n\nfor sample in $id; do\n        source=$(awk -F\"\\t\" -v sample=\"$sample\" '$1 == sample {print $1}' ../../data/metadata.tsv)\n        r1=$(echo -e $sample\"_1.fastq.gz\"\",\"\"forward\")\n        r2=$(echo -e $sample\"_2.fastq.gz\"\",\"\"reverse\")\n        path=$(pwd)\n        echo -e $source\",\"$path\"/\"$r1 &gt;&gt; ../../data/manifest.csv\n        echo -e $source\",\"$path\"/\"$r2 &gt;&gt; ../../data/manifest.csv\ndone"
  }
]