[
  {
    "objectID": "Binning.html",
    "href": "Binning.html",
    "title": "Genomas a partir de metagenomas",
    "section": "",
    "text": "La metagen√≥mica hace referencia a todo el ADN de los organismos que se encuentran en un ambiente. La secuenciaci√≥n de este material gen√©tico produce lecturas que pueden ensamblarse para conocer la diversidad microbiana y sus funciones.\nT√≠picamente los metagenomas pueden estudiarse mediante dos aproximaciones:\nEn este apartado nos enfocaremos en la segunda aproximaci√≥n. Los MAGs se reconstruyen a partir de un ensamble metagen√≥mico, los contigs de dicho ensamble se agrupan mediante la informaci√≥n de cobertura y frecuencia de tetranucle√≥tidos. Esta agrupaci√≥n puede generar errores, por lo que es indispensable evaluar la calidad de los MAGs mediante la completitud y redundancia de genes de copia √∫nica (MerenLab y col.)\nPara obtener MAGs podemos seguir el siguiente flujo de an√°lisis:"
  },
  {
    "objectID": "Binning.html#binning",
    "href": "Binning.html#binning",
    "title": "Genomas a partir de metagenomas",
    "section": "Binning",
    "text": "Binning\nEn la secci√≥n anterior aprendimos como evaluar la calidad, filtrar las lecturas y a ensamblarlas, por lo que este apartado comenzar√° con el ensamble ya generado.\nDe acuerdo con el flujo de an√°lisis (Figura 2), debemos partir de un ensamble y mapear las lecturas a dicho ensamble para obtener un archivo de profundidad de cada contig en el ensamble.\n\n\n\n\n\n\nNota\n\n\n\nEl proceso de mapeo es demandante en tiempo de ejecuci√≥n y recursos. As√≠ que nos dimos a la tarea de generar el archivo de profundidad para comenzar directamente con el binning.\nEl mapeo lo corrimos con bowtie2 que es una herramienta confiable y muy utilizada para alinear lecturas cortas a una referencia, en nuestro caso, la referencia es el ensamble metagen√≥mico de la muestra de 48hrs. Bowtie2 genera un archivo de mapeo (SAM) que debe convertirse a un formato binario (BAM), para esta conversi√≥n usamos samtools que contiene multiples subherramientas para trabajar con archivos de mapeos.\nPara generar este archivo se utilizaron las siguientes lineas de c√≥digo.\n# Formatear el ensamble\nbowtie2-build results/02.ensambles/megahit/48hrs/48hrs.fasta results/03.profundidad/48hrs --threads 40\n# Mapear las lecturas contra el ensamble\nbowtie2 -x results/03.profundidad/48hrs -1 data/48hrs_sm_R1.fastq -2 data/48hrs_sm_R2.fastq -p 40 -S results/03.profundidad/48hrs.sam\n# Convertir de SAM a BAM y ordenar\nsamtools view -Sb -O BAM -@ 40 results/03.profundidad/48hrs.sam | samtools sort -@ 40  -o results/03.profundidad/48hrs_sorted.bam\n# Obtener el √≠ndice\nsamtools index results/03.profundidad/48hrs_sorted.bam\nYa que generamos el archivo bam ordenado y el √≠ndice obtuvimos un archivo con la informaci√≥n de cobertura de cada contig dentro del ensamble, este archivo de profundidad se gener√≥ con jgi_summarize_bam_contig_depths que es una herramienta de metabat.\n# jgi\n#Obtener el archivo de profundidad de cada contig\njgi_summarize_bam_contig_depths  --outputDepth results/03.profundidad/48hrs.mgh_depth.txt results/03.profundidad/48hrs_sorted.bam\n\n\n\n\n\n\nAtenci√≥n\n\n\n\nNo las ejecutes, s√≥lo son un ejemplo para que las puedas usar con tus propios datos en el futuro.\n\n\n\n\n\n\n\n\n\n\n\n\nEjercicio\n\n\n\nAntes de comenzar, re√∫nete con tu equipo y juntos\n\nrevisen el contenido de los directorios 02.ensambles y 03.profundidad.txt\nDiscutan y en una diapositiva expliquen el flujo que se sigui√≥ para obtener los archivos que estan esos directorios\n\nLa liga de drive para ir trabajando durante el taller es esta: https://drive.google.com/drive/folders/1iKfhMz_JdfImmsCmkPg10r-NC-nrzhQ4?usp=sharing\n\n\nS√≥lo por si te pierdes\n\n\n\n\n\n\nDirectorio de trabajo\n\n\n\nSi en alg√∫n momento te pierdes entre directorios, puedes regresar al espacio principal asi:\ncd && cd taller_metagenomica_pozol/\n\n\n\n\nMetabat2\nMetabat2 es una herramienta que agrupa los contigs tomando la cobertura de cada contig y calcula su composici√≥n nucleot√≠dica.\nPara correr metabat necesitamos activar el ambiente conda donde se aloja.\n\n\n\n\n\n\nActivar ambiente para Metabat2\n\n\n\n\nbetterlab\nconda activate binning\n\n\n\n\n\n\nMetabat2. Kang et al., 2015. DOI:10.7717/peerj.1165\n\n\nAhora que ya tenemos el ambiente activado ejecutemos la siguiente linea:\nmetabat2 -i results/02.ensambles/48hrs.fasta -a results/03.profundidad/48hrs.mgh_depth.txt -o results/04.metabat/metabat -t 4 -m 1500\n\n\n\n\n\n\nResponde:\n\n\n\n\n\n\n¬øCu√°ntos bins se formaron?\n\n2. ¬øQu√© par√°metros cambiar√≠as o agregar√≠as?\n\n\n\n\n\n\nAyuda\n\n\n\n\n\n\nls results/04.metabat/\nmetabat2 ‚Äì-help\n\n\n\n\n\n\n\nYa que corrimos Metabat2 vamos a ejecutar MaxBin2, pero primero necesitamos desactivar el ambiente:\n\n\n\n\n\n\nDesactiva el ambiente\n\n\n\nPara desactivar el ambiente debemos correr la siguiente linea:\nconda deactivate\n\n\n\n\nMaxBin2\nMaxBin2 agrupa los contigs de acuerdo a la informaci√≥n de cobertura, composici√≥n nucleot√≠dica y genes de marcadores de copia √∫nica.\nVamos a ejecutarlo, activemos el ambiente conda para maxbin.\n\n\n\n\n\n\nActivar ambiente para MaxBin2\n\n\n\n\nbetterlab\nconda activate metagenomics\n\n\n\n\n\n\nMaxBin2. Wu et al., 2014. https://doi.org/10.1186/2049-2618-2-26\n\n\nCrea el directorio para los resultados de MaxBin2\nmkdir -p results/05.maxbin\nAhora si, vamos a ejecutarlo.\n\nrun_MaxBin.pl -thread 4 -min_contig_length 1500 -contig results/02.ensambles/48hrs.fasta -out results/05.maxbin/48hrs_maxbin -abund results/03.profundidad/48hrs.mgh_depth.txt\n\n\n\n\n\n\nEjercicio:\n\n\n\n\n\n1. ¬øCu√°ntos bins se formaron?\n2. ¬øQu√© porcentaje de completitud y contaminaci√≥n tienen??\n\n\n\n\n\n\nSoluci√≥n\n\n\n\n\n\n\nls results/05.maxbin/*.fasta | wc -l\ncat results/05.maxbin/48hrs_maxbin.summary | column -t\n\n\n\n\n\n\n\n\n\n\n\n\n\nDesactiva el ambiente\n\n\n\nconda deactivate\n\n\n\n\nVamb\nVAMB utiliza una combinaci√≥n de enfoques de aprendizaje profundo y t√©cnicas de agrupamiento bas√°ndose en sus patrones de composici√≥n de nucle√≥tidos y en la co-ocurrencia de sus frecuencias de cobertura.\n\n\n\n\n\n\nActiva el ambiente binning\n\n\n\n\nbetterlab\nconda activate binning\n\n\n\nVamos a correr vamb, pero primero crea el directorio de resultados\nmkdir -p results/06.vamb\nEjecutemos vamb:\nvamb --fasta results/02.ensambles/48hrs.fasta --jgi results/03.profundidad/48hrs.mgh_depth.txt --minfasta 500000 --outdir results/06.vamb/48hrs\n\n\n\n\n\n\nImportant\n\n\n\nSi quisieras recuperar los genomas de virus ¬øQu√© par√°metro cambiar√≠as?\n\n\n\n\n\n\n\n\nOtros programas para binning\n\n\n\nRecientemente se public√≥ COMEBin, que utiliza un enfoque distinto a lo que hemos usado en este tutorial. En el siguiente link encontrar√°s el manual y una explicaci√≥n general sobre su funcionamiento."
  },
  {
    "objectID": "Binning.html#refinamiento",
    "href": "Binning.html#refinamiento",
    "title": "Genomas a partir de metagenomas",
    "section": "Refinamiento",
    "text": "Refinamiento\nYa corrimos tres programas de binning, pero, recordemos que los agrupamientos pueden tener errores:\n\n\n\nContaminaci√≥n de bins\n\n\nPara disminuir la contaminaci√≥n e incrementar la completitud hay algunos programas que pueden ayudarnos. entre ellos est√°n Binning_refiner y DASTool.\n\nCheckM\nAntes de proceder al refinamiento es necesario tener claro c√≥mo se eval√∫a la completitud y contaminaci√≥n de los bins. Para esta evaluaci√≥n se usa CheckM que se ha convertido en una herramienta est√°ndar para la evaluaci√≥n de la calidad de genomas y MAGs y es usada por la mayor√≠a de programas de refinamiento.\nPara hacer esta evaluaci√≥n CheckM utiliza una serie de herramientas: tree organiza los genomas en un √°rbol de referencia. tree_qa eval√∫a la cantidad de genes marcadores filogen√©ticos y su ubicaci√≥n en el √°rbol. El comando lineage_set crea un archivo de marcadores espec√≠ficos de linaje, que se usa en el comando analyze para evaluar la integridad y contaminaci√≥n de los genomas. Finalmente, el comando qa genera tablas que resumen la calidad de los genomas.\n\n\n\nCheckM Workflow\n\n\nEn este taller no vamos a correr CheckM porque los programas de refinamiento que usaremos ya lo corren de forma interna, sin embargo es √∫til correrlo para tener una idea clara sobre la calidad de los bins que obtengamos.\nTe dejamos la siguiente l√≠nea para que la uses en tus proyectos, adem√°s, en este repositorio encontrar√°s los scripts que pueden ser √∫tiles para extraer los bins que cumplan la calidad que buscas:\n#ejemplo de como correrlo con los bins de vamb\n#se debe activar el ambiente metagenomics\n#checkm lineage_wf results/06.vamb/48hrs/bins results/checkm/ -x fna -t 4  -f results/checkm/checkm_vamb_bins.txt\n\n\nBinning_refiner\nBinning_refiner se enfoca en refinar y fusionar los bins para mejorar la integridad y reducir la contaminaci√≥n. Identifica bins que pueden representar el mismo genoma y los fusiona. Despu√©s elimina posibles contaminaciones, durante el proceso Binning_refiner eval√∫a la calidad de los bins.\n\n\n\nBinning_refiner\n\n\nhttps://doi.org/10.1093/bioinformatics/btx086\nNecesitamos crear el directorio de resultados para binning_refiner y un directorio con los bins generados por cada programa\nmkdir -p results/07.binning_refiner/48hrsbins/{metabat,maxbin,vamb}\nAhora vamos a crear ligas simb√≥licas de los bins generados por cada herramienta.\n#metabat\ncd results/07.binning_refiner/48hrsbins/metabat/\n\nln -s ../../../04.metabat/*.fa .\n\n#maxbin\ncd ../maxbin/\nln -s ../../../05.maxbin/*.fasta .\n\n# vamb\ncd ../vamb/\nln -s ../../../06.vamb/48hrs/bins/*.fna .\n\n\n#regresar\ncd ../../\nAhora si, corramos Binning_refiner\nBinning_refiner -i 48hrsbins/ -p 48hrs\nY regresemos a nuestro directorio principal\ncd && cd taller_metagenomica_pozol/\nExploremos los resultados!\ncat results/07.binning_refiner/48hrs_Binning_refiner_outputs/48hrs_sources_and_length.txt\nRefined_bin     Size(Kbp)       Source\n48hrs_1 1535.49 48hrs_maxbin.004.fasta,metabat.5.fa,676.fna\n48hrs_2 1506.01 48hrs_maxbin.002.fasta,metabat.3.fa,6952.fna\n48hrs_3 1319.12 48hrs_maxbin.008.fasta,metabat.2.fa,28067.fna\n48hrs_4 1263.79 48hrs_maxbin.005.fasta,metabat.9.fa,3736.fna\n48hrs_5 1185.25 48hrs_maxbin.001.fasta,metabat.11.fa,15732.fna\n48hrs_6 1052.67 48hrs_maxbin.003.fasta,metabat.4.fa,15732.fna\n48hrs_7 557.49  48hrs_maxbin.006.fasta,metabat.1.fa,28990.fna\nAbre el archivo src/sankey.R o copia y pega este contenido en la consola de Rscript\n# Cargar las librerias\nlibrary(dplyr)\nlibrary(networkD3)\n\n# revisa tu ubicaci√≥n\ngetwd()\nsetwd(\"/home/alumno2/taller_metagenomica_pozol\")\n\n# Cargar los datos\nsankey_data &lt;- read.csv(\"results/07.binning_refiner/48hrs_Binning_refiner_outputs/48hrs_sankey.csv\")\n\n# Crear una lista de nodos √∫nicos\nnodes &lt;- data.frame(name = unique(c(sankey_data$C1, sankey_data$C2)))\n\n# Crear el dataframe de enlaces\nlinks &lt;- sankey_data %&gt;%\n  mutate(source = match(C1, nodes$name) - 1,\n         target = match(C2, nodes$name) - 1,\n         value = Length_Kbp) %&gt;%\n  select(source, target, value)\n\n# Crear el gr√°fico Sankey\nsankey_plot &lt;- sankeyNetwork(Links = links, Nodes = nodes,\n                             Source = \"source\", Target = \"target\",\n                             Value = \"value\", NodeID = \"name\",\n                             fontSize = 12, nodeWidth = 30)\n\n# Mostrar el gr√°fico\nsankey_plot\n\n# Guardar\nlibrary(htmlwidgets)\nsaveWidget(sankey_plot, file = \"48hrs_sankey_plot.html\")\n\n\n\nBinning_refiner sankey plot\n\n\n\n\nDASTool\nDASTool es una herramienta utilizada para mejorar la calidad de los bins. Eval√∫a la integridad, combina los resultados de diferentes bineadores y por consenso selecciona los mejores bins de cada herramienta. Una vez que DASTool ha seleccionado los mejores bins, realiza un proceso de refinamiento para optimizar los resultados.\n\n\n\nDASTool\n\n\nVamos a correr DASTool ‚Ä¶\nPrimero crea el directorio para los resultados\nmkdir -p results/08.dastool\nDASTool necesita como entrada un archivo tabular con informaci√≥n de los resultados de cada programa de binning.\nFasta_to_Contig2Bin.sh -i results/04.metabat/ -e fa &gt; results/08.dastool/48hrs_metabat.dastool.tsv\n\nFasta_to_Contig2Bin.sh -i results/05.maxbin/ -e fasta &gt; results/08.dastool/48hrs_maxbin.dastool.tsv\n\nFasta_to_Contig2Bin.sh -i results/06.vamb/48hrs/bins/ -e fna &gt; results/08.dastool/48hrs_vamb.dastool.tsv\n\nFasta_to_Contig2Bin.sh -i results/07.binning_refiner/48hrs_Binning_refiner_outputs/48hrs_refined_bins/ -e fasta &gt; results/08.dastool/48hrs_binningrefined.dastool.tsv\nYa que tenemos los archivos tsv podemos empezar con el refinamiento!! ü•≥\nDAS_Tool -i results/08.dastool/48hrs_metabat.dastool.tsv,results/08.dastool/48hrs_maxbin.dastool.tsv,results/08.dastool/48hrs_vamb.dastool.tsv,results/08.dastool/48hrs_binningrefined.dastool.tsv -l metabat,maxbin,vamb,binning_refined -c results/02.ensambles/48hrs.fasta -o results/08.dastool/48hrs -t 4 --write_bins"
  },
  {
    "objectID": "Binning.html#dereplicaci√≥n",
    "href": "Binning.html#dereplicaci√≥n",
    "title": "Genomas a partir de metagenomas",
    "section": "Dereplicaci√≥n",
    "text": "Dereplicaci√≥n\n\ndRep\nLa desreplicaci√≥n es el proceso de identificar conjuntos de genomas que son ‚Äúiguales‚Äù en una lista de genomas y eliminar todos los genomas excepto el ‚Äúmejor‚Äù de cada conjunto redundante. dRep es una herramienta √∫til para esto.\n\n\n\ndRep\n\n\nmkdir -p results/09.drep/bins\ncd results/09.drep/bins/\nfor i in $(ls ../../08.dastool/48hrs_DASTool_bins/*.fa) ; do name=$(basename $i .fa); cp $i $name\".fasta\" ; done\n\ncp ../../07.binning_refiner/48hrs_Binning_refiner_outputs/48hrs_refined_bins/*.fasta .\ncd && cd taller_metagenomica_pozol/\n#export PATH=/miniconda3/envs/metagenomics/bin:$PATH\ndRep dereplicate results/09.drep/ -d -comp 50 -con 10 --SkipSecondary -g results/09.drep/bins/*.fasta\n\n\n\ndRepWinningGenomes\n\n\nconda deactivate"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "El pozol",
    "section": "",
    "text": "El pozol es un alimento √°cido, fermentado a partir de ma√≠z nixtamalizado. No se inocula y al final de su fermentaci√≥n tiene alta diversidad microbiana.\nüß¨üîäü¶† Imaginemos que se quiere impulsar la producci√≥n de esta bebida y para ello necesitan saber todo acerca de su naturaleza microbiana. Secuenciaron cuatro puntos de fermentaci√≥n de muestras que se obtuvieron en un mercado de Campeche. Las muestras se secuenciaron con Illumina NextSeq500 con lecturas pareadas de 75 pb.\nUna importante industria alimenticia los contacta como expertos en ecolog√≠a microbiana y les pide ayuda para descubrir los siguientes puntos:\n\n¬øQu√© actores microbianos est√°n presentes durante el proceso de fermentaci√≥n?\n¬øC√≥mo ocurre la bioconversi√≥n del ma√≠z durante la fermentaci√≥n, qui√©n participa y c√≥mo lo hace? ¬øQu√© funciones metab√≥licas est√°n ocurriendo?\n¬øHay potenciales pat√≥genos?\n¬øCambia la comunidad microbiana a lo largo del proceso?\n\n\n\n\n\n\n\nImportante\n\n\n\nComo las muestras contienen ma√≠z, es indispensable remover las lecturas que correspondan al genoma del ma√≠z, no hacerlo producir√° un ensamble muy fragmentado, mayoritariamente del ma√≠z y poco microbiano.\nEl autor del art√≠culo amablemente nos proporcion√≥ sus muestras libres del ma√≠z y el c√≥digo que us√≥ para ello est√° disponible en un repositorio p√∫blico de GitHub.\n\n\nEl art√≠culo: L√≥pez-S√°nchez et al., 2023. Analysing the dynamics of the bacterial community in pozol, a Mexican fermented corn dough. 10.1099/mic.0.001355"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Microbioma_del_pozol",
    "section": "",
    "text": "En este taller introductorio aprenderemos a reconstruir genomas a partir de metagenomas (MAGs), a clasificar los MAGs taxon√≥micamente y a predecir sus genes e inferir su metabolismo. Adem√°s, abordaremos un poco sobre el an√°lisis de amplicones del gene 16S ARNr."
  },
  {
    "objectID": "index.html#taller-introductorio-al-an√°lisis-de-metagenomas-centrado-en-genomas-y-an√°lisis-de-amplicones-del-gene-16s-arnr.",
    "href": "index.html#taller-introductorio-al-an√°lisis-de-metagenomas-centrado-en-genomas-y-an√°lisis-de-amplicones-del-gene-16s-arnr.",
    "title": "Microbioma_del_pozol",
    "section": "",
    "text": "En este taller introductorio aprenderemos a reconstruir genomas a partir de metagenomas (MAGs), a clasificar los MAGs taxon√≥micamente y a predecir sus genes e inferir su metabolismo. Adem√°s, abordaremos un poco sobre el an√°lisis de amplicones del gene 16S ARNr."
  },
  {
    "objectID": "index.html#temario",
    "href": "index.html#temario",
    "title": "Microbioma_del_pozol",
    "section": "Temario",
    "text": "Temario\nD√≠a 3\n\n\n\nHora\nTema\n\n\n\n\n9:00 - 9:30\nReconstrucci√≥n de genomas\n\n\n9:30 - 9:50\n¬øQu√© es el binning?\n\n\n9:50 - 10:00\nDescanso\n\n\n10:00 - 12:15\nReconstrucci√≥n de genomas\n\n\n12:15 - 12:30\nDescanso\n\n\n12:30 - 13:30\nEjercicio por equipo\n\n\n13:30 - 14:00\nDiscusi√≥n de resultados\n\n\n14:00 - 15:30\nComida\n\n\n15:30 - 16:00\nDereplicaci√≥n\n\n\n16:00 - 17:00\nClasificaci√≥n taxon√≥mica\n\n\n\nD√≠a 4\n\n\n\n\n\n\n\nHora\nTema\n\n\n\n\n9:00 - 10:00\nPredicci√≥n g√©nica\n\n\n10:00 - 10:30\nPl√°tica sobre el microbioma del chinicuil\n\n\n10:30 - 10:45\nDescanso\n\n\n10:45 - 12:00\nRbims\n\n\n12:00 - 12:15\nDescanso\n\n\n12:15 - 14:00\nOtras inferencias metab√≥licas y discusi√≥n de resultados\n\n\n14:00 - 15:30\nComida\n\n\n15:30 - 17:00\nVistazo a la reconstrucci√≥n viral y eucari√≥tica\n\n\n\nD√≠a 5\n\n\n\n\n\n\n\nHora\nTema\n\n\n\n\n9:00 - 10:00\nIntroducci√≥n al an√°lisis de amplicones\n\n\n10:00 - 10:30\nIntroducci√≥n a QIIME2\n\n\n10:30 - 10:45\nDescanso\n\n\n10:45 - 12:00\nImportaci√≥n de datos e inferencia de ASVs\n\n\n12:00 - 12:15\nDescanso\n\n\n12:15 - 14:00\nAsignaci√≥n taxon√≥mica, limpieza e inferencia filogen√©tica\n\n\n14:00 - 15:30\nComida\n\n\n15:30 - 17:00\nImportaci√≥n a R, gr√°ficos y diversidad"
  },
  {
    "objectID": "Project.html",
    "href": "Project.html",
    "title": "Preparemos todo para el proyecto",
    "section": "",
    "text": "Reglas del juego\n\n\n\n\nEn este tutorial haremos el ejemplo corriendo la muestra de 48 hrs.\nSe formaran 6 equipos (2 de los tiempos 0, 9 y 24 hrs).\nLos equipos discutir√°n y presentar√°n sus resultados cuando se indique en el tutorial."
  },
  {
    "objectID": "Project.html#espacio-de-trabajo",
    "href": "Project.html#espacio-de-trabajo",
    "title": "Preparemos todo para el proyecto",
    "section": "Espacio de trabajo",
    "text": "Espacio de trabajo\n\nEntra a tu cuenta en el servidor y sit√∫ate en tu $HOME\nObten los datos y la estructura de tu directorio del proyecto corriendo lo siguiente:\n\ncd\ncp -r /home/alumno1/pozol_data/taller_metagenomica_pozol\n\nEntra al directorio del proyecto\n\ncd taller_metagenomica_pozol\n\n\n\n\n\n\nDirectorio de trabajo\n\n\n\nSi en alg√∫n momento te pierdes entre directorios, puedes regresar al espacio principal asi:\ncd && cd taller_metagenomica_pozol/\n\n\n\nLa presente pr√°ctica s√≥lo es una representaci√≥n del flujo de trabajo para el an√°lisis metagen√≥mico, sin embargo, no sustituye los manuales de cada programa y el flujo puede variar dependiendo del tipo de datos y pregunta de investigaci√≥n, de hecho para fines del taller, con frecuencia se utilizan las lineas de comando m√°s simples para eficientar tiempo y recursos, t√≥malo en cuenta.\n\nCada programa tiene una ayuda y un manual de usuario, es importante revisarlo y conocer cada par√°metro que se ejecute. En terminal se puede consultar el manual con el comando man y tambi√©n se puede consultar la ayuda con -h o --help, por ejemplo fastqc -h.\n\n\n\n\n\n\nImportant\n\n\n\nüß† Para tenerlo presente\nEn bioinform√°tica cualquier l√≠nea de comandos generar√° un resultado, de ah√≠ a que esos resultados sean correctos puede haber una gran diferencia.\nEn cada paso detente a revisar la informaci√≥n de cada programa, lee el manual, visita foros de ayuda y selecciona los argumentos que se ajusten a las necesidades de tus datos."
  },
  {
    "objectID": "metabolic.html",
    "href": "metabolic.html",
    "title": "Metabolismo",
    "section": "",
    "text": "PROKKA\nconda activate Prokka_Global\nmkdir -p results/11.prokka\nfor FASTA in $(ls results/10.gtdbtk/bins/); do\n    LOCUSTAG=$(basename $FASTA .fasta)\n    prokka --locustag \"${LOCUSTAG}_Scaffold\" \\\n           --prefix $LOCUSTAG \\\n           --addgenes \\\n           --addmrna \\\n           --cpus 4 \\\n           --outdir \"results/11.prokka/$LOCUSTAG\" \\\n           \"results/10.gtdbtk/bins/$FASTA\"\ndone\n rm -r results/12.kofam/tmp48hBin0*\nconda deactivate\n\nKOFAM\nmkdir -p results/12.kofam\nfor FAA in $(ls results/11.prokka/*/*.faa); do\n    name=$(basename $FAA .faa)\n    exec_annotation $FAA \\\n        -o results/12.kofam/\"$name.txt\" \\\n        --report-unannotated \\\n        --cpu 4 \\\n        --tmp-dir results/12.kofam/\"tmp$name\" \\\n        -p /home/alumno1/kofam/db/profiles/ \\\n        -k /home/alumno1/kofam/db/ko_list\ndone\nrm -r results/12.kofam/tmp*\n\n\nRBiMS"
  },
  {
    "objectID": "gtdbtk.html",
    "href": "gtdbtk.html",
    "title": "Asignaci√≥n taxon√≥mica",
    "section": "",
    "text": "GTDB-tk\nGTDB-Tk es una herramienta que asigna taxonom√≠a a genomas utilizando la base de datos GTDB (Genome Taxonomy Database). Basado en √°rboles filogen√©ticos y medidas de ANI (Average Nucleotide Identity), GTDB-Tk clasifica genomas bacterianos y arqueanos, proporciona una taxonom√≠a coherente y actualizada. Se utiliza mucho en el an√°lisis de genomas y metagenomas.\n\n\n\nGTDB-tk Workflow\n\n\nRecordemos que ya tenemos un set de bins refinados y desreplicados. Ahora vamos a asignarles identidad taxon√≥mica, para ello vamos a correr GTDB-tk\n\n\n\n\n\n\nActiva el ambiente de gtdbtk\n\n\n\nconda activate gtdbtk-2.1.1\n\n\nCrea el directorio de resultados para gtdbtk, copia y renombra los bins:\nbash src/copiar_renombrar_bins_para_gtdb.sh\nAhora si, vamos a correrlo\npip install numpy==1.19.5\n\nnohup gtdbtk classify_wf --genome_dir results/10.gtdbtk/bins/ --out_dir results/10.gtdbtk/ --cpus 4 -x fasta &gt; gtdbtk.nohup &\nNo olvides desactivar el ambiente\nconda deactivate\nDespu√©s de ejecutar GTDB-tk, continuaremos en R para visualizar los datos.\nlibrary(tidyverse)\nlibrary(ggplot2)\n\nGTDBK &lt;- read.table(\"results/10.gtdbtk/gtdbtk.bac120.summary.tsv\", \n  sep = \"\\t\", header = TRUE, na.strings = \"\", stringsAsFactors = FALSE) %&gt;%\n  as_tibble()\n\n#El archivo contiene informaci√≥n sobre la clasificaci√≥n taxon√≥mica de los bins.\n#Continuamos limpiando y transformando los datos:\n\npozol_gtdbtk &lt;- GTDBK %&gt;%\n  select(user_genome, classification) %&gt;%\n  separate(classification, c(\"Domain\", \"Phylum\", \"Class\", \"Order\", \"Family\", \"Genus\", \"Species\"), sep = \";\") %&gt;%\n  rename(Bin_name = user_genome) %&gt;%\n  unite(Bin_name_2, c(\"Bin_name\", \"Phylum\"), remove = FALSE) %&gt;%\n  select(Bin_name, Domain, Phylum, Class, Order, Family, Genus, Species)\n\n#Guardamos los datos en un archivo de metadatos:\nwrite.table(pozol_gtdbtk, file = \"results/10.gtdbtk/Metadatos.txt\", sep = \"\\t\", quote = FALSE, row.names = FALSE, col.names = TRUE)\n\n#Visualizaci√≥n de Datos Creamos un gr√°fico de barras  que muestra la distribuci√≥n taxon√≥mica de los bins:\n\nGTDBtk_barplot &lt;- pozol_gtdbtk %&gt;%\n  count(Phylum, Genus) %&gt;%\n  rename(Number_of_MAGs = n) %&gt;%\n  ggplot(aes(x = Phylum, y = Number_of_MAGs, fill = Genus)) + \n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  theme_minimal()\n\nGTDBtk_barplot\n\n\n\n\n\n\nDiscusi√≥n\n\n\n\nEn equipos revisen los resultados generados por GTDB-tk y propongan un plan para mejorar la identificaci√≥n taxon√≥mica, qu√© har√≠an para darle m√°s soporte a estos resultados?"
  },
  {
    "objectID": "Amplicones16S.html",
    "href": "Amplicones16S.html",
    "title": "Amplicones 16S",
    "section": "",
    "text": "Qiime2 (Quantitative Insights Into Microbial Ecology) es un pipeline desarrollado para el an√°lisis de metataxonom√≠a (Bolyen et al., 2019). Contiene herramientas para limpiar secuencias, agrupar, asignar taxonom√≠a, reconstruir filogenias, inferir m√©tricas de diversidad, abundancia diferencial, etc. Es de c√≥digo abierto, posee una interfaz gr√°fica amigable, mucha documentaci√≥n, tutoriales y foros de ayuda.\nRecordemos el flujo de an√°lisis que se pueden hacer dentro de este pipeline."
  }
]